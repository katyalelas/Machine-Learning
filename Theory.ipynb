{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML divisions of what it does?\n",
    "If you want to predict a CATEGORY - it is classification\n",
    "f.e. whether the stock price will increase or decrease. yes or no\n",
    "\n",
    "Predict quantity? Thats regression.\n",
    "f.i. predict the age of a person based on the height, weight, health\n",
    "\n",
    "Anomaly detection. f.i. money withdraw anomaly or for predicting the stock market, it is a different prediction model?\n",
    "\n",
    "Do you want to discover structure in unexplored data? That is clustering. \n",
    "f.i. finding groups of customers with similar behavior given a large database of customer data containing their demographics and past buying records\n",
    "explore the group \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quizz\n",
    "1) grouping documents into different categories based on the topic and content of each document / clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Identifying hand-written digits and images correctly / classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) behavior of a website indication that the site is not working as designed / anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) predictiong salary of an individual based on his years of experience / regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning / a method used to enable machines to classify or predict objects, problems, or situations based on labeled data fed to the machine. Labels and features. You already know the answers for many problems, sutiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised learning / machine find a fidden pattern in unlabeled data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinforecement learning. learns by performing actions and seeing the results (reword or punishment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised (labeled data, direct feedback, predict output (for prediction?)) VS Unsupervised (non labeled data, no feedback, find hidden structure in data (for grouping? for finding the label?))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised Learning: Regression and Classification (KNN, Random Forest (decision tree), Naive Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y=mx+c\n",
    "m = slope (positive relations)\n",
    "c = y-intercept of line\n",
    "\n",
    "you line should pass throught the mean of (x, y)\n",
    "m = (sum (x-xi)(y-yi) )/(sum (x-xi)2)\n",
    "\n",
    "c= y(mean) - mx(mean) \n",
    "\n",
    "then you compare predictive values and real onces. analyse an error\n",
    "how to minimize the error? SUm of Squared erros, Sum of Absolute errors, Root mean square error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desicion tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "suggestions\n",
    "ENTROPY AND INFORMATION GAIN, Root Node - the attribute with the largest information gain, Branch Node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "myImage = Image.open(\"DT.png\");\n",
    "myImage.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine (classification algorithm): the algorithm creates a separation line which divides the classes in the best possible manner. dog or cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have labeled sample data... a new data point arrives and we need to figure out set it to a pafrticular group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance margin: the distance between the hyperplane and the nearest data point from either set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or Randon Decision Forest is a method that operates by constructing multiple Decision Trees during training phase. The decision of the majority of the trees is chosen by the random forest as the final decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a tree shaped diagram used to determine a course of action. Each branch of the tree represents a possible decision, occurrence ot reaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "used in ETM devices to acquire images of the earths surface; object detection; Kinet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy - is the measure if randomness ir unpredictability in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High entropy E1 - after spliitng - low entropy E2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information gain E1-E2 - is the measure of decrease in entropy after the dataset split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaf Note carries the classification or the decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Note has two or more branches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root Node the top most decision node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does a decision tree work?\n",
    "Problem statement. The dataset (has hight entropy). Training dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to split the data so that Information gain is the highest.  By splitting the data using each condition and checking the gain that we get out them. The condition that gives us the highest gain will be used to make the first split (f.e. base on color, diameter - False/True). We need to achieve 0 entropy, so we would have 100% accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "myImage = Image.open(\"RF.png\");\n",
    "myImage.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Random Forest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. No overfitting (ise of multiple trees reduce the risk of overfitting, training time is less)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. High Accuracy - runs efficientntly on large database. For large data, it produces highly accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Estimates missing data. Can maintain accuracy when a large proportiion of data is missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "organizing objects into groups based on their similarity. \n",
    "K means clustering - unsupervised learning. based on features similarity. in K means we pick \"K\" clusters and assign random centroids to clusters.Then we compare distance from objects to centroids. And we form new clusters based on minimum distance and calculate their centroids. Repeat previous two steps iteratively till the cluster centroids stop changing their positions and become static. Once the clusters become static then k-means clustering algo is said to be converged. Converged on an answer - has come to a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Choose K (Elbow Method)\n",
    "2. Assign random centroids to clusters\n",
    "3. Compute distance from objects to centroids\n",
    "4. Form new clusters based on minimum distance and calculate their centroids\n",
    "5. Compute distance from objects to new centroids\n",
    "Repeat 5,4 until no observations change groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the rigth value of K will help in less number of iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WSS (Within sum of squares) is defined as the sum of the squared distance between each memeber of the cluster and its centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the optimal number of clusters using the elbow of the graph is called as the Elbow Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(K - how many clusters)\n",
    "K means is used in academic performance, diagnostic systems, search engines, wireless sensor networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of clustering: Hierarchical clustering ( Agglomerative & Divisive) and Partitional Clustering (K means / Fuzzy C means)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agglomerative - bottom up approach: begim with each element as a separate cluster and merge them into successively larger clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divisive - Top down approach begin with the whole set and proceed to divide it into successively smaller clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means - division of objects into clusters such that each object is in exactly one cluster, not several"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuzzy C-means - division of objects into clusters such that each object can belong to multiple clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance measure will determine the similarity between two elements and it will influence the shape of the clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Euclidean distance measure - distance between two points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Squared euclidean distance measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manhattan distance measure - sum of the horizontal and vertical components or the distance between two points measured along axes at right angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine distance measure - measures the angle between the two vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disadvantages of K-Means\n",
    "The number of clusters has to be set in the beginning\n",
    "The results depend on the inital cluster centers\n",
    "It's sensitive to outliers\n",
    "It's not suitable for finding non-convex clusters\n",
    "It's not guaranteed to find a global optimum, so it can get stuck in a local minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classification algorithm that is used to predict the probability of a categorical dependent variable. In logistic regression, the dependent variable is a binary variable that contains data coded as 1 (yes, success, etc.) or 0 (no, failure, etc.). In other words, the logistic regression model predicts P(Y=1) as a function of X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Binary logistic regression requires the dependent variable to be binary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For a binary regression, the factor level 1 of the dependent variable should represent the desired outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Only the meaningful variables should be included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. The independent variables should be independent of each other. That is, the model should have little or no multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. The independent variables are linearly related to the log odds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Logistic regression requires quite large sample sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of the support vector machine algorithm is to find a hyperplane in an N-dimensional space(N — the number of features) that distinctly classifies the data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "easy-to-implement supervised machine learning algorithm that can be used to solve both classification and regression problems. (A regression problem has a real number (a number with a decimal point) as its output.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It assumes that similar things exist in close proximity. In other words, similar things are near to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN Algorithm\n",
    "1. Load the data\n",
    "2. Initialize K to your chosen number of neighbors\n",
    "3. For each example in the data\n",
    "\n",
    "3.1 Calculate the distance between the query example and the current example from the data.\n",
    "\n",
    "3.2 Add the distance and the index of the example to an ordered collection\n",
    "\n",
    "4. Sort the ordered collection of distances and indices from smallest to largest (in ascending order) by the distances\n",
    "\n",
    "5. Pick the first K entries from the sorted collection\n",
    "\n",
    "6. Get the labels of the selected K entries\n",
    "\n",
    "7. If regression, return the mean of the K labels\n",
    "\n",
    "8. If classification, return the mode of the K labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is a classification algorithm for binary (two-class) and multi-class classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes’ Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
